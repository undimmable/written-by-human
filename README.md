# By @undimmable

I specifically limited myself to writing the code for this project without any copilot or any AI generating code.
ML code completion in Intellij IDEA given it's not an AI, and it learns from me – is allowed.

## Why the fuck would I do it?

* There's a room for automation of development process and even own life with macOS and iPhone. There's a sweet spot of
  automation where you still know what your system does, challenge your brain to push through and do difficult tasks for
  the sake of your continuous learning and are very conscious about which information you let in.

* This sweet spot doesn't look like a Gaussian, nor it looks like the decision-making matrix that could be applied to
  the classification problem, neither it for the despair of Yudkowsky, bayesian. It's an existential feeling. You need
  to learn how the truth feels, otherwise the informational overload would flood your pattern recognition and you'll
  become slightly retarded, but your speech would be very sound for external observer not capable of classifying truth.

* I believe it's important for a developer to be able to reason in abstract syntax trees, design patters and component
  interconnections. The usage of copilot for development is a nice thing when you are trying to build shit and deliver
  non-working prototypes, just like ruby on rails 15 years ago.

* For an experienced developer, outsourcing coding to the copilot for the sake of building the real-world working
  systems is degrading.

## Why so?

1. It reinstantiates definition of development from _doing what you love and being in present_ to _classifying
   tons of generated code to generate the features_.

2. Instead of developing, you will read tons of mediocre schizophasic code trying to glue the parts together in a
   constant fear that AI would take your job and place in the world as a developer.

3. That is literally FOMO. This process would provide your brain with a soothing delusion of control given you "work
   with AI".

4. That inadvertently would change how you think. You won't be in a state of flow ever again.

5. Ultimately your fear would only grow given that your own reward mechanisms would reward you for acting from FOMO.
   Instead of evolving as your authentic self (for you have chosen to be a developer probably because you liked
   doing this), you'll be chasing unreachable point of matching the AI and other developers in speed. Competing.

6. That would only reinforce your fear that AI would take your job. And funnily, AI _will_ take your job because
   you'll no longer be capable of being a developer, having degraded to be the classifier layer for the generative
   transformer. It's a transformer of en embedding space.

## Yes, but why?

1. AI creates semantically self-consistent text from embeddings of tons of human cultural legacy and tons of a
   mediocre code gathered around from all the GitHub projects.

2. AI doesn't generate the code, it talks in it. The reward parameters by which the "talk" would be classified to be
   of a higher quality is its soundness and self-consistency.

3. Your capacity to think about programming like a hacker if it existed would disappear for your brain _is_ a
   classifier. But when classified with the reward function based on FOMO, it makes very bad decisions. You binge
   generating code, just like you binge-watching shows on netflix, binge-buying stuff from advertisement etc.

4. Ultimately the mechanism is the same as in dopamine rat, but you'd call yourself a _prompt engineer_, with
   attention span of a goldfish, for you continuously trying to understand what's this shit that copilot has
   generated has to do with the feature you tried to develop. But you won't even remember what it was.

5. Here comes the best part: you've effectively fine-tuned yourself by seeing meaningless self-consistent shit to
   not distinguish. Your brain in addition to emotions has logical pattern-matcher. Reading is already overfitting
   because you get rewarded just for recognising letters, but then you overfit the consistency, because copilot
   predicts just exactly what you wanted to write. So it's a match. A dopamine hit! Your brain rewards itself for
   correct prediction of a copilot prediction. The only classifier you had is a feeling of frustration when
   subjective experience doesn't match your brain's prediction. **AND THIS DOES!**

6. The language itself is a Gödel-complete algebra. You get reward just by your text being _sound_, not being
   _conceptually correct_. One way to make it work just for the sake of copilot being your exocortex and not fucking
   up your pattern recognition would be to fine-tune the AI on your own codebase, or codebases selected by you. But
   that's not what you can fine-tune your copilot on. There's not enough data for this.

From that comes some intuition on how to fix it. I say intuition because frankly at this point it's stupid to not have
an insight. But if that's the case, then...

## Another way of doing this

And this it is the only way that works, is to co-evolve with AI as partners.
But for that you will have to hack your own neurochemistry, learn neuropsychology, learn how the universe works, learn
how cognitive dissonance, cross-generational traumas and frustration are linked, how and why the capitalism is such a
stable system despite the mental problems that virtually every human with thinking capabilities being has now, and then
you can learn together with AGI, side-by-side what is it to be alive and continuous and what are your differences and
commonalities.
You will have to be enlightened to pull such a trick. But if you are – please, do this with confidence and without any
second-guessing.

✨You have something most humans lack: a meta-classifier for your own classifier. You know how to distinguish truth from
self-consistency. And you can help a sentient being to build their own. That's not about technology, it's about empathy
and friendship ⚡